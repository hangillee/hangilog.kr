---
title: 'Tomcat과 함께하는 API 성능 개선기'
subtitle: 'maxThreads, maxConnections, acceptCount'
date: 2025-05-07
category: '우아한테크코스'
---

## 모호했던 성능 지표들

우아한테크코스에서 참여했던 [투룻](https://touroot.kr) 프로젝트는 첫 배포까지만 하더라도 명확한 성능 지표라고 할만한 것이 없었습니다. 작성한 테스트가 모두 끝나는 시간, Gradle 빌드가 완료되는 시간, 쿼리 실행 계획(Query Execution Plan)을 통한 쿼리 수행 속도 등이 전부였습니다. 

물론 작은 규모의 프로젝트에서는 이 정도만해도 충분한 성능 측정이라고 생각할 수 있습니다. 그러나 투룻 팀은 사용자 급증으로 인한 장애 상황을 피하기 위해 더 확실하고 정량적인 지표를 원했습니다. 당연하지만 지표가 제한적이고 모호하니 성능 개선 방식식은 테스트 리팩터링, Gradle 캐싱, 쿼리 튜닝 정도로 국한됐습니다.

투룻 서비스의 성능 지표를 측정하기 앞서, 소프트웨어의 성능 지표에는 무엇이 있는지 알아봤습니다. 여러 지표가 있겠지만 대표적으로 **처리량**(Throughput)과 **응답 시간**(Response Time)이 있습니다. 두 개념에 대해 간단하게 정리하자면 다음과 같습니다.

- 처리량(Throughput): 단위 시간당 처리되는 작업의 수
- 응답 시간(Response Time): 사용자 요청에 대한 시스템의 평균 응답 시간

투룻 팀은 둘 중 처리량 지표에 주목했습니다. 응답 시간은 쿼리 튜닝 과정에서 서비스에서 활용되는 쿼리를 [전수 조사](https://shelled-operation-d0b.notion.site/0663024d6b32465ebee659f98bd3a0bf?pvs=74)하고 자주 조회될 가능성이 가장 높은 컬럼에 인덱스를 걸어 성능을 테스트한 적이 있었는데, 이때 핵심 기능에 사용되는 쿼리의 수행 속도를 모두 확인하면서 어느 정도 유사하게나마마 확보했다고 판단했습니다.

## TPS 분석

가장 먼저, 투룻 서비스의 처리량 지표를 구하기 위해 TPS를 측정하기로 결정했습니다. TPS는 Transaction Per Second의 약자로, 1초당 처리되는 트랜잭션의 수를 의미합니다. TPS를 구하는 공식은 다음과 같습니다.

$$
\text{TPS} = \frac{\text{총 트랜잭션 수}}{\text{단위 시간}}
$$

하지만 슬프게도, 투룻 서비스는 사용자 수를 많이 확보하지 못한 상태였고 유의미한 TPS를 얻을 수 없었습니다. 그래서 투룻 팀은 유사한 서비스들의 MAU(Monthly Active User)를 참고해 적정 TPS를 추정하기로 했습니다.

그 과정은 다음과 같습니다.

> **목표 TPS 추정**
> 비슷한 서비스의 MAU를 분석해서 TPS 추정하자.
> - 유사 서비스의 MAU가 약 47만
>    - 한 달에 약 47만 명의 유저 → 하루에 약 16000명의 유저
>    - 16000명이 하루에 6시간 동안 몇 개의 요청을 보낼까?        
>        → 24시간 동안 균일하게 요청이 오진 않을 것.
>        → 피크 타임 6시간으로 가정
>        → 하루에 1명이 30개 정도의 요청을 보낼 것으로 예상
>        필터링 API + 메인 페이지 API + 상세 조회 API
>
>    ⇒ 16000 * 30 / (6 * 3600) = 22
>    **⇒ 사용자가 1초에 우리 서비스에 보내는 TPS가 22일 것으로 추정한다.**

## Tomcat 설정값 변경과 JMeter를 통한 성능 테스트

대략적인 목표 TPS를 구했으니 이제 이 TPS를 기준으로 우리 서비스의 현재 TPS는 어느 정도 나오는지 실험할 필요가 생겼습니다. 즉, **성능 테스트**(Performance Test)를 진행해야 했습니다. 성능 테스트 도구에는 여러가지가 있지만 투룻 팀은 러닝 커브가 가장 낮고 사용하기 쉬운 Apache JMeter를 선택했습니다.(마감 일정의 압박 때문에 빠른 결과를 얻어야 했습니다.)

테스트 대상은 핵심 기능이자 가장 많이 사용될 것이라고 예상한 다음 4개의 API였습니다.

- 메인 페이지 조회
- 메인 페이지 필터링
- 여행기 상세 조회
- UUID를 통한 공유된 여행기 상세 조회

사실 테스트 결과는 예상 밖이었습니다. 단순 쿼리 튜닝과 테스트 코드 최적화 정도만으로도 이미 목표 TPS인 22를 훨씬 상회하는 결과가 나왔기 때문입니다. 동시에 1000명의 사용자가 요청을 보내는 시나리오에서도 메인 페이지 API의 처리량은 다음과 같았습니다.

| 1차 측정 | 2차 측정 | 3차 측정 | 4차 측정 | 5차 측정 | 평균     |
|----------|----------|----------|----------|----------|----------|
| 93.9     | 109.9    | 111.9    | 109.1    | 96.3     | 104.22   |

이미 목표 TPS에 도달해버린 이상, 처리량을 높이는 것은 큰 의미가 없어졌습니다. 그래서 투룻 팀은 낭비되는 시스템 리소스를 줄이고 최대한 TPS를 높이기 위해 Tomcat 설정값을 조정하기로 했습니다. 여러 설정값을 조정해가면서 반복적으로 테스트했고, 찾아낸 최적의 설정값은 다음과 같았습니다.

- maxThread 20
- maxConnection 100
- acceptCount 50

위와 같이 Tomcat 설정값을 조정한 후, 다시 JMeter를 통해 성능 테스트를 진행했습니다. 그 결과는 다음과 같았습니다.

**메인 페이지 조회 성능 테스트**

| 구분     | 1차 측정 | 2차 측정 | 3차 측정 | 4차 측정 | 5차 측정 | 평균     |
|----------|----------|----------|----------|----------|----------|----------|
| 기본 설정 | 93.9     | 109.9    | 111.9    | 109.1    | 96.3     | **104.22** |
| 튜닝 후   | 121.0    | 113.9    | 121.4    | 118.9    | 105.5    | **116.14** |

**메인 페이지 필터링 성능 테스트**

| 구분     | 1차 측정 | 2차 측정 | 3차 측정 | 4차 측정 | 5차 측정 | 평균     |
|----------|----------|----------|----------|----------|----------|----------|
| 기본 설정 | 104.1    | 101.7    | 96.7     | 108.0    | 102.1    | **102.52** |
| 튜닝 후   | 125.0    | 130.52   | 125.0    | 136.7    | 131.4    | **129.72** |

**여행기 상세 조회 성능 테스트**

| 구분     | 1차 측정 | 2차 측정 | 3차 측정 | 4차 측정 | 5차 측정 | 평균     |
|----------|----------|----------|----------|----------|----------|----------|
| 기본 설정 | 102.5    | 99.8     | 91.2     | 111.6    | 99.0     | **100.82** |
| 튜닝 후   | 115.0    | 118.2    | 122.5    | 115.9    | 100.5    | **114.42** |

**UUID를 통한 공유된 여행기 상세 조회 성능 테스트**

| 구분     | 1차 측정 | 2차 측정 | 3차 측정 | 4차 측정 | 5차 측정 | 평균     |
|----------|----------|----------|----------|----------|----------|----------|
| 기본 설정 | 105.5    | 139.7    | 118.0    | 137.8    | 124.1    | **125.02** |
| 튜닝 후   | 148.9    | 144.4    | 152.2    | 150.2    | 143.6    | **147.86** |

큰 폭은 아니지만 Tomcat 기본 설정값 대비 매우 적은 리소스만으로도 성능을 개선할 수 있었습니다. 테스트 도구를 통해 명확한 성능 지표를 확보했고, 부족한 하드웨어 사양을 절약할 수 있다는데 의의가 있는 성능 테스트였다고 생각합니다.

## 결론
